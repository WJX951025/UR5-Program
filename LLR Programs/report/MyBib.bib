% This file was created with JabRef 2.3.1.
% Encoding: Cp1252

@ARTICLE{SchaalAtkeson:94, 
title={Robot juggling: implementation of memory-based learning}, 
author={Schaal, S. and Atkeson, C.G.}, 
journal={Control Systems Magazine, IEEE}, 
year={1994}, 
month={Feb}, 
volume={14}, 
number={1}, 
pages={57-71}, 
keywords={learning systems, nonlinear control systems, optimal control, robots, statistical analysisexploration algorithm, fast real-time learning, locally weighted regression, memory-based local modeling, optimal control, robot juggling, robot learning, statistical tests}, 
doi={10.1109/37.257895}, 
ISSN={0272-1708}, 
}

@book{Berg:00,
  author = {Mark de Berg and Marc van Kreveld and Mark Overmars and Otfried Schwarzkopf},
  edition = {Second},
  interhash = {56b511e262f19ac52d0aefa0470202e5},
  intrahash = {700334e7df2fbf7c4e88479b011cb848},
  pages = 367,
  publisher = {Springer-Verlag},
  title = {Computational Geometry: Algorithms and Applications},
  url = {http://www.cs.uu.nl/geobook/},
  year = 2000,
  keywords = {graphics cairo library algorithms},
  description = {Computational Geometry textbook},
  biburl = {http://www.bibsonomy.org/bibtex/2700334e7df2fbf7c4e88479b011cb848/cairo},
}



@report{Moore:91,
    Year = {1991},
    Booktitle = {University of Cambridge Computer Laboratory Technical Report No. 209},
    Note = {Available from http://www.cs.cmu.edu/\~awm},
    Author = {Andrew Moore},
    Title = {A tutorial on kd-trees}
}


@INPROCEEDINGS{Bakker:06,
  author = {Bram Bakker and Viktor Zhumatiy and Gabriel Gruener and J{\"u}rgen
	Schmidhuber},
  title = {Quasi-online Reinforcement Learning for Robots},
  booktitle = {ICRA},
  year = {2006},
  pages = {2997-3002},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  crossref = {DBLP:conf/icra/2006}
}

@INPROCEEDINGS{Boutilier:96,
    author = {Craig Boutilier},
    title = {Planning, Learning and Coordination in Multiagent Decision Processes},
    booktitle = {In TARK},
    year = {1996},
    pages = {195--210},
    publisher = {Morgan Kaufmann}
}

@MISC{Aha:98,
  author = {David W. Aha},
  title = {Feature Weighting for Lazy Learning Algorithms},
  year = {1998},
  address = {Boston},
  pages = {13-32},
  publisher = {Kluwer Academic},
  volume = {SECS 453}
}

@INPROCEEDINGS{vanAstBabuska:06,
  author = {Jelmer van Ast and Robert Babuska},
  title = {Dynamic Exploration in Q(lambda)-learning},
  booktitle = {IJCNN},
  year = {2006},
  pages = {41-46}
}

@INPROCEEDINGS{AtkesonSchaal:97,
  author = {Atkeson, Christopher G. and Schaal, Stefan},
  title = {Robot Learning From Demonstration},
  booktitle = {ICML '97: Proceedings of the Fourteenth International Conference
	on Machine Learning},
  year = {1997},
  pages = {12--20},
  address = {San Francisco, CA, USA},
  publisher = {Morgan Kaufmann Publishers Inc.},
  isbn = {1-55860-486-3}
}

@INPROCEEDINGS{BakkerSchmidhuber:04,
  author = {Bram Bakker and J�rgen Schmidhuber},
  title = {Hierarchical Reinforcement Learning Based on Subgoal Discovery and
	Subpolicy Specialization},
  booktitle = {Proceedings of the 8-th Conference on Intelligent Autonomous Systems,
	IAS-8},
  year = {2004},
  pages = {438--445}
}

@TECHREPORT{Bakker:03,
  author = {Bram Bakker and Viktor Zhumatiy and Gabriel Gruener and J�rgen Schmidhuber},
  title = {A Robot that Reinforcement-Learns to Identify and Memorize Important
	Previous Observations},
  institution = {In Proceedings of the 2003 IEEE/RSJ International Conference on Intelligent
	Robots and Systems},
  year = {2003}
}

@BOOK{Bellman:57,
  title = {Dynamic programming},
  publisher = {Princeton University Press, Princeton},
  year = {1957},
  author = {Bellman, Richard},
  type = {Book}
}

@BOOK{Rencher:08,
	title = {Linear Models in Statistics},
	author = {Rencher, Alvin C},
	type = {Book},
	publisher = {Wiley-Interscience},
	year = {2008}
}



@PHDTHESIS{Benbrahim:96,
  author = {Benbrahim, Hamid},
  title = {Biped dynamic walking using reinforcement learning},
  year = {1996},
  address = {Durham, NH, USA},
  note = {Director-Miller,III, W. Thomas},
  isbn = {0-591-26032-8},
  order_no = {AAI9717850},
  publisher = {University of New Hampshire}
}

@INPROCEEDINGS{Boone:97,
  author = {Gary Boone},
  title = {Efficient Reinforcement Learning: Model-Based Acrobot Control},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = {1997},
  pages = {229--234}
}

@ARTICLE{Cook:79,
	author = {Cook, R. D.},
	year = {1979},
	title = {Influence Observations in Linear Regression},
	journal = {Journal of American Statistical Association},
	volume = {74},
	pages = {169-174},
}



@ARTICLE{Atkeson:97a,
  author = { Chris Atkeson, Andrew Moore, Stefan Schaal },
  title = {Locally Weighted Learning},
  journal = {AI Review},
  year = {1997},
  volume = {11},
  pages = {11-73},
  month = {April},
  publisher = {Kluwer}
}

@ARTICLE{Busoniu:10,
	author = {L. Busoniu, D. Ernst, B. De Schutter, R. Babuska},
	title = {Approximate Dynamic Programming with a Fuzzy Parametrization},
	journal = {Automatica},
	volume = {46},
	number = {5},
	pages = {804-814},
	year = {2010}
}

@INPROCEEDINGS{Degris:06,
  author = {Degris, Thomas and Sigaud, Olivier and Wuillemin, Pierre-Henri},
  title = {Learning the structure of Factored Markov Decision Processes in reinforcement
	learning problems},
  booktitle = {ICML '06: Proceedings of the 23rd international conference on Machine
	learning},
  year = {2006},
  pages = {257--264}
}

@BOOK{DorigoColombetti:98,
  title = {Robot Shaping: An Experiment in Behavior Engineering},
  publisher = {MIT Press},
  year = {1998},
  author = {Marco Dorigo and M. Colombetti},
  address = {Cambridge, MA},
  keyword = {robotics}
}


@ARTICLE{Friedman:77,
    address = {New York, NY, USA},
    author = {Friedman, Jerome H. and Bentley, Jon L. and Finkel, Raphael A.},
    issn = {0098-3500},
    journal = {ACM Trans. Math. Softw.},
    keywords = {clustering, kd-tree},
    month = {September},
    number = {3},
    pages = {209--226},
    publisher = {ACM Press},
    title = {An Algorithm for Finding Best Matches in Logarithmic Expected Time},
    url = {http://dx.doi.org/10.1145/355744.355745},
    volume = {3},
    year = {1977}
}

@INPROCEEDINGS{FriedmanGoldxzmidt:97,
  author = {Friedman, Nir and Goldszmidt, Moises},
  title = {Sequential update of Bayesian network structure},
  booktitle = {Proceedings of the Thirteenth Conference on Uncertainty in Artificial
	Intelligence},
  year = {1997},
  pages = {165--174}
}

@INPROCEEDINGS{Gaskett:99,
  author = {Chris Gaskett and David Wettergreen and Alexander Zelinsky and Er
	Zelinsky},
  title = {Q-Learning in Continuous State and Action Spaces},
  booktitle = {Australian Joint Conference on Artificial Intelligence},
  year = {1999},
  pages = {417--428}
}

@PHDTHESIS{Gordon:99,
  author = {Geoffrey J. Gordon},
  title = {Approximate Solutions to Markov Decision Processes},
  school = {Carnegie Mellon University},
  year = {1999}
}

@MISC{Gordon:95,
  author = {Geoffrey J. Gordon},
  title = {Stable Function Approximation in Dynamic Programming},
  year = {1995}
}

@INPROCEEDINGS{Grzes:08,
  author = {Grze\'{s}, Marek and Kudenko, Daniel},
  title = {An Empirical Analysis of the Impact of Prioritised Sweeping on the
	DynaQ's Performance},
  booktitle = {ICAISC '08: Proceedings of the 9th international conference on Artificial
	Intelligence and Soft Computing},
  year = {2008},
  pages = {1041--1051},
  isbn = {978-3-540-69572-1}
}

@TECHREPORT{Heckerman:96,
  author = {David Heckerman},
  title = {A Tutorial on Learning With Bayesian Networks},
  institution = {Learning in Graphical Models},
  year = {1996}
}

@ARTICLE{HochreiterSchmidhuber:97,
  author = {S. Hochreiter and J. Schmidhuber},
  title = {Long Short Term Memory},
  journal = {Neural Computation},
  year = {1997},
  volume = {9},
  pages = {1735-1780}
}

@ARTICLE{Kaelbling:96,
  author = {Kaelbling, L. P. and Littman, M. L. and Moore, A. W.},
  title = {Reinforcement Learning: {A} Survey},
  journal = {Journal of Artificial Intelligence Research},
  year = {1996},
  volume = {4},
  pages = {237--285}
}

@INPROCEEDINGS{KuvayevSutton:96,
  author = {Leonid Kuvayev and Rich Sutton},
  title = {Model-Based Reinforcement Learning with an Approximate, Learned Model},
  booktitle = {Proceedings of the Ninth Yale Workshop on Adaptive and Learning Systems},
  year = {1996},
  pages = {101--105}
}

@INPROCEEDINGS{Lin:92,
  author = {Long-ji Lin},
  title = {Self-improving reactive agents based on reinforcement learning, planning
	and teaching},
  booktitle = {Machine Learning},
  year = {1992},
  pages = {293--321}
}

@INPROCEEDINGS{Lin:93,
  author = {Long Ji Lin},
  title = {Scaling Up Reinforcement Learning for Robot Control},
  booktitle = {ICML},
  year = {1993},
  pages = {182-189},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@INPROCEEDINGS{Mahadevan:96,
  author = {Sridhar Mahadevan},
  title = {Machine Learning for Robots: A Comparison of Different Paradigms},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems
	(IROS-96)},
  year = {1996}
}

@INPROCEEDINGS{Mataric:94,
  author = {Maja J Mataric},
  title = {Reward Functions for Accelerated Learning},
  booktitle = {Proceedings of the Eleventh International Conference on Machine Learning},
  year = {1994},
  pages = {181--189},
  publisher = {Morgan Kaufmann}
}

@MISC{MichaudMataric:99,
  author = {Francois Michaud and Maja J Matari\&apos;c},
  title = {Representation of behavioral history for learningin nonstationary
	conditions},
  year = {1999}
}

@ARTICLE{MooreAtkeson:93,
  author = {Andrew W. Moore and Christopher G. Atkeson},
  title = {Prioritized Sweeping: Reinforcement Learning With Less Data and Less
	Time},
  journal = {Machine Learning},
  year = {1993},
  volume = {13},
  pages = {103--130},
  comment = {!P},
  owner = {ThijsR},
  publisher = {Kluwer Academic Publishers, Boston},
  timestamp = {2009.05.29}
}

@ARTICLE{MooreAtkeson:95,
  author = {Andrew W. Moore and Christopher R. Atkeson},
  title = {The Parti-Game Algorithm for Variable Resolution Reinforcement Learning
	in Multidimensional State-spaces},
  journal = {Machine Learning},
  year = {1995},
  volume = {21},
  pages = {199--233},
  comment = {!P},
  owner = {Administrator}
}

@ARTICLE{MunosMoore:01,
  author = {R\'{e}mi Munos and Andrew Moore},
  title = {Variable-Resolution Discretization in Optimal Control},
  journal = {Machine Learning},
  year = {2001},
  volume = {1},
  pages = {1--31},
  owner = {Administrator},
  timestamp = {2006.09.05}
}

@INPROCEEDINGS{Ng:99,
  author = {Andrew Y. Ng and Daishi Harada and Stuart Russell},
  title = {Policy invariance under reward transformations: Theory and application
	to reward shaping},
  booktitle = {Proceedings of the Sixteenth International Conference on Machine
	Learning},
  year = {1999},
  pages = {278--287},
  publisher = {Morgan Kaufmann}
}

@INPROCEEDINGS{Ng:04,
  author = {Andrew Y. Ng and H. Jin Kim and Michael I. Jordan and Shankar Sastry},
  title = {Autonomous Helicopter Flight via Reinforcement Learning},
  booktitle = {International Symposium on Experimental Robotics},
  year = {2004},
  publisher = {MIT Press}
}

@INPROCEEDINGS{PengWilliams:93,
  author = {Jing Peng and Ronald J. Williams},
  title = {Efficient Learning and Planning Within the Dyna Framework},
  booktitle = {Adaptive Behavior},
  year = {1993},
  pages = {437--454}
}

@MISC{Peters:03,
  author = {Jan Peters and Sethu Vijayakumar and Stefan Schaal},
  title = {Reinforcement Learning for Humanoid Robotics},
  year = {2003}
}

@INPROCEEDINGS{RandlovAlstrom:98,
  author = {Randl�v, Jette and Alstr�m, Preben},
  title = {Learning to Drive a Bicycle Using Reinforcement Learning and Shaping},
  booktitle = {ICML '98: Proceedings of the Fifteenth International Conference on
	Machine Learning},
  year = {1998},
  pages = {463--471},
  address = {San Francisco, CA, USA},
  publisher = {Morgan Kaufmann Publishers Inc.},
  isbn = {1-55860-556-8}
}

@INPROCEEDINGS{Rayner:07,
  author = {Chris D. Rayner and Katherine Davison and Vadim Bulitko and Kenneth
	Anderson and Jieshan Lu},
  title = {Real-Time Heuristic Search with a Priority Queue},
  year = {2007},
  pages = {2372 - 2377},
  journal = {Proceedings of the International Joint Conference on Artificial Intelligence
	(IJCAI)}
}

@INPROCEEDINGS{Riedmiller:05,
  author = {Martin Riedmiller},
  title = {Neural fitted Q iteration � first experiences with a data efficient
	neural reinforcement learning method},
  booktitle = {16th European Conference on Machine Learning},
  year = {2005},
  pages = {317--328},
  publisher = {Springer}
}

@TECHREPORT{RummeryNiranjan:94,
  author = {G. A. Rummery and M. Niranjan},
  title = {On-Line Q-Learning Using Connectionist Systems},
  year = {1994}
}

@ARTICLE{Santamaria:98,
  author = {Juan Carlos Santamar�a and Juan Carlos Santamar'ia and Richard S.
	Sutton and Ashwin Ram},
  title = {Experiments with Reinforcement Learning in Problems with Continuous
	State and Action Spaces},
  journal = {Adaptive Behavior},
  year = {1998},
  volume = {6},
  pages = {163--218}
}

@INPROCEEDINGS{SchaalAtkeson:95,
  author = {Stefan Schaal and Christopher G. Atkeson},
  title = {Robot Learning by Nonparametric Regression},
  booktitle = {Proceedings of Intelligent Robots and Systems 1994 (IROS �94},
  year = {1995},
  pages = {137--154}
}

@INPROCEEDINGS{Schmidhuber:91,
  author = {J�rgen Schmidhuber},
  title = {Curious Model-Building Control Systems},
  booktitle = {Proc. International Joint Conference on Neural Networks, Singapore},
  year = {1991},
  pages = {1458--1463},
  publisher = {IEEE}
}

@MASTERSTHESIS{Schuitema:06,
  author = {Schuitema, Erik},
  title = {Hierarchical reinforcement learning},
  school = {Delft University of Technology},
  year = {2006},
  owner = {ThijsR},
  timestamp = {2009.07.08}
}

@INPROCEEDINGS{SmartKaelbling:00,
  author = {William D. Smart and Leslie Pack Kaelbling},
  title = {Practical Reinforcement Learning in Continuous Spaces},
  year = {2000},
  pages = {903--910},
  publisher = {Morgan Kaufmann}
}

@INPROCEEDINGS{Sutton:96,
  author = {Richard S. Sutton},
  title = {Generalization in Reinforcement Learning: Successful Examples Using
	Sparse Coarse Coding},
  booktitle = {Advances in Neural Information Processing Systems 8},
  year = {1996},
  pages = {1038--1044},
  publisher = {MIT Press}
}

@INPROCEEDINGS{Sutton:95,
  author = {Richard S. Sutton},
  title = {Generalization in Reinforcement Learning: {S}uccessful Examples Using
	Sparse Coarse Coding},
  booktitle = {Advances in Neural Information Processing Systems 8 ({NIPS-95})},
  year = {1995},
  pages = {1038--1044},
  address = {Denver,US},
  month = {27--30 November},
  owner = {ThijsR},
  timestamp = {2009.05.29}
}

@INPROCEEDINGS{Sutton:91a,
  author = {Richard S. Sutton},
  title = {{DYNA}, an Integrated Architecture for Learning, Planning and Reacting},
  booktitle = {Working Notes {AAAI} Spring Symposium on Integrated Intelligent Architectures},
  year = {1991},
  owner = {ThijsR},
  timestamp = {2009.05.29},
  url = {citeseer.ist.psu.edu/sutton91dyna.html},
  xref = {A024}
}

@INPROCEEDINGS{Sutton:91b,
  author = {Richard S. Sutton},
  title = {Integrated Modeling and Control Based on Reinforcement Learning and
	Dynamic Programming},
  booktitle = {Advances in Neural Information Processing Systems 3 (The 1991 Neural
	Information Processing Systems Conference, {NIPS-91})},
  year = {1991},
  pages = {471--478},
  address = {Denver, Colorado, USA},
  month = {November 26--29},
  comment = {!P},
  owner = {Administrator},
  timestamp = {2007.02.16}
}

@INPROCEEDINGS{Sutton:90,
  author = {Richard S. Sutton},
  title = {Integrated Architectures for Learning, Planning, and Reacting Based
	on Approximating Dynamic Programming},
  booktitle = {Proceedings Seventh International Conference on Machine Learning
	(ICML-90)},
  year = {1990},
  pages = {216--224},
  address = {Austin, Texas, US},
  month = {June 21--23},
  comment = {!P},
  owner = {Administrator},
  timestamp = {2007.01.25}
}

@ARTICLE{Sutton:88,
  author = {Richard S. Sutton},
  title = {Learning to Predict by the Methods of Temporal Differences},
  journal = {Machine Learning},
  year = {1988},
  volume = {3},
  pages = {9--44},
  owner = {ThijsR},
  timestamp = {2009.05.29}
}

@BOOK{SuttonBarto:98,
  title = {Reinforcement Learning: {A}n Introduction},
  publisher = {MIT Press},
  year = {1998},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  address = {Cambridge, US},
  comment = {!P},
  owner = {ThijsR},
  timestamp = {2009.05.29},
  xref = {BK002}
}

@ARTICLE{SuttonMcAllesteretal:00,
  author = {Richard S. Sutton and David McAllester and Satinder Singh and Yishay
	Mansour},
  title = {Policy Gradient Methods for Reinforcement Learning with Function
	Approximation},
  journal = {Advances in Neural Information Processing Systems},
  year = {2000},
  volume = {12},
  pages = {1067--1063},
  booktitle = {Proceedings 12th Conference on Advances in Neural Information Processing
	Systems},
  owner = {ThijsR},
  timestamp = {2009.05.29}
}

@INPROCEEDINGS{Sutton:08,
  author = {Sutton, R. S. and Szepesvari, Cs and Geramifard, A. and Bowling,
	M.},
  title = {Dyna-Style Planning with Linear Function Approximation and Prioritized
	Sweeping},
  booktitle = {Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence},
  year = {2008},
  pages = {528--536},
  posted-at = {2008-09-03 13:09:41},
  url = {http://www.cs.ualberta.ca/\%7Esutton/papers/SSGB-08.pdf}
}

@INPROCEEDINGS{Tadepalli:96,
  author = {Prasad Tadepalli and Dokyeong Ok},
  title = {Scaling Up Average Reward Reinforcement Learning by Approximating
	the Domain Models and the Value Function},
  booktitle = {Saitta},
  year = {1996},
  pages = {471--479},
  publisher = {Morgan Kaufmann}
}

@INPROCEEDINGS{Taylor:06,
  author = {Taylor, Matthew E. and Whiteson, Shimon and Stone, Peter},
  title = {Comparing evolutionary and temporal difference methods in a reinforcement
	learning domain},
  booktitle = {GECCO '06: Proceedings of the 8th annual conference on Genetic and
	evolutionary computation},
  year = {2006},
  pages = {1321--1328}
}

@ARTICLE{Tesauro:95,
  author = {Tesauro, Gerald},
  title = {Temporal Difference Learning and {TD-Gammon}},
  journal = {Communications of the ACM},
  year = {1995},
  volume = {38},
  pages = {58--68},
  number = {3},
  month = mar
}

@INPROCEEDINGS{ThrunSchwartz:93,
  author = {Sebastian Thrun and Anton Schwartz},
  title = {Issues in Using Function Approximation for Reinforcement Learning},
  booktitle = {Proceedings of the Fourth Connectionist Models Summer School},
  year = {1993}
}

@ARTICLE{TsitsiklisVanRoy:97,
  author = {John N. Tsitsiklis and Benjamin {Van Roy}},
  title = {An Analysis of Temporal Difference Learning with Function Approximation},
  journal = {IEEE Transactions on Automatic Control},
  year = {1997},
  volume = {42},
  pages = {674--690},
  number = {5},
  month = {May},
  xref = {A023}
}

@MASTERSTHESIS{Vaandrager:08,
  author = {Vaandrager, Maarten},
  title = {Using prior knowledge to accelerate reinforcement learning},
  school = {Delft University of Technology},
  year = {2008},
  owner = {ThijsR},
  timestamp = {2009.07.08}
}

@PHDTHESIS{Watkins:89,
  author = {Christopher J. C. H. Watkins},
  title = {Learning from Delayed Rewards},
  school = {King's College, Oxford},
  year = {1989},
  month = may,
  xref = {PHD001}
}

@ARTICLE{WatkinsDayan:92,
  author = {Watkins, Christopher J. C. H. and Dayan, Peter},
  title = {Q-Learning},
  journal = {Machine Learning},
  year = {1992},
  volume = {8},
  pages = {279--292},
  number = {3},
  month = {May},
  keywords = {pad, reinforcementlearning}
}

@ARTICLE{Wingate:05,
  author = {Wingate, David and Seppi, Kevin D.},
  title = {Prioritization Methods for Accelerating MDP Solvers},
  journal = {J. Mach. Learn. Res.},
  year = {2005},
  volume = {6},
  pages = {851--881},
  address = {Cambridge, MA, USA},
  issn = {1533-7928},
  publisher = {MIT Press}
}


